The learning and planning system:
agent keeps record of the history of its actions and changes of its internal state(health) and the external states(like previous, present tile location, how far or near it is from destination) also timestep..

Monitor the changes of the contents of each records in the history. To monitor and create inference use a clustering(k-means maybe) or unsupervised learning and feed in either changes of the contents or the contents themselves. The first time protagonist approaches antagonist by smelling, the odor intensity increases with every movement and so suppose this event happens 3 times and 3 times the clustering algorithm records a pattern and thus when the protagonist touches the antagonist, antagonist attacks, protagonist's health decreases. The goal is to minimise protagonist's health decrease at all cost and so as health decrease suceeds the pattern of odor intensity increase, the agent infers and connects this pattern to inside its brain graph to health decrease(negative reward). Thus by temporal difference learning, this pattern achieves negative reward and agent wont ever try to repeat this particular odor pattern. The clustering algorithm will only be run when any even is related to gain or loss of rewards. That clustering algorithm should also record the maximum odour of different things. Suppose for one antagonist it is 30, other one is 40. They have distinct odours. Thus the clustering algorithm should also help in finding distance between antagonist and protagonist and protagonist thus locates the antagonist in the environment state space.

Variables:
1) time step
2) Health level
3) Box position and their number
4) Odour intensity 
5) health value of food
6) speed of both agents(depends on health and exhaustion level)
7) Exhaustion level
8) History level.

